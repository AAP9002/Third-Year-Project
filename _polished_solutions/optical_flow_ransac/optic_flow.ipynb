{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optic Flow Experiment Demo\n",
    "Inspired by: A Robust Road Vanishing Point Detection Adapted to the\n",
    "Real-World Driving Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the:\n",
    "1. analysis\n",
    "2. stable motion detection\n",
    "3. stationary point-based motion vector selection\n",
    "4. angle-based RANSAC\n",
    "(RANdom SAmple Consensus) voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_WITH_YOLO_SEG = True\n",
    "file = \"10 sec video 1 mototrway crash h.264.mp4\"\n",
    "START_FRAME = 0\n",
    "RUN_UP = False\n",
    "RUN_UP_FRAMES = 40\n",
    "END_FRAME = None\n",
    "OUTPUT_FOLDER = None\n",
    "\n",
    "STANDARD_RESOLUTION = (2560, 1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python numpy matplotlib ultralytics --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Process input and output paths for video processing.\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"-i\", \"--input\", \n",
    "    help=\"Path to the input video file.\", \n",
    "    required=False\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"-o\", \"--output\", \n",
    "    help=\"Path to the output folder.\", \n",
    "    required=False\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"-s\", \"--start_frame\", \n",
    "    help=\"Starting frame number for processing.\",\n",
    "    required=False\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"-e\", \"--end_frame\", \n",
    "    help=\"Ending frame number for processing.\",\n",
    "    required=False\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"-r\", \"--run_up\", \n",
    "    help=\"Run up the video processing.\",\n",
    "    action=\"store_true\",\n",
    "    required=False\n",
    ")\n",
    "\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--f\", \"--kernel_launcher\", \n",
    "    help=\"Path to the kernel launcher file.\",\n",
    "    required=False\n",
    ")\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.input and args.output:\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    file = args.input\n",
    "    OUTPUT_FOLDER = args.output\n",
    "    if args.start_frame:\n",
    "        START_FRAME = int(args.start_frame)\n",
    "    if args.end_frame:\n",
    "        END_FRAME = int(args.end_frame)\n",
    "\n",
    "    if args.run_up:\n",
    "        # add run up frames to the start frame\n",
    "        RUN_UP = True\n",
    "        START_FRAME = START_FRAME - RUN_UP_FRAMES\n",
    "    print(\"System arguments detected:\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cli call\n",
    "if OUTPUT_FOLDER:\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "else:\n",
    "    OUTPUT_FOLDER = \"temp/\" + file.split(\".\")[0]\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "cap = cv2.VideoCapture(file)\n",
    "total_number_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "RESOLUTION = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "if RESOLUTION != STANDARD_RESOLUTION:\n",
    "    print(f\"Warning: Video resolution is {RESOLUTION}, expected {STANDARD_RESOLUTION}.\")\n",
    "    print(\"This may cause issues with the processing.\")\n",
    "else:\n",
    "    print(f\"Video resolution is {RESOLUTION}, as expected.\")\n",
    "\n",
    "# END_FRAME = 80 # Manual test override\n",
    "\n",
    "print(f'Processing file: {file}')\n",
    "print(f'Total number of frames: {total_number_of_frames}')\n",
    "print(f'Output folder: {OUTPUT_FOLDER}')\n",
    "print(f'Start frame: {START_FRAME}')\n",
    "print(f'End frame: {END_FRAME}')\n",
    "\n",
    "# frame range check\n",
    "if START_FRAME < 0:\n",
    "    raise ValueError(\"Start frame cannot be negative.\")\n",
    "if END_FRAME and END_FRAME > total_number_of_frames:\n",
    "    raise ValueError(\"End frame cannot be greater than total number of frames.\")\n",
    "if END_FRAME and END_FRAME < START_FRAME:\n",
    "    raise ValueError(\"End frame cannot be less than start frame.\")\n",
    "if END_FRAME is None:\n",
    "    END_FRAME = total_number_of_frames\n",
    "\n",
    "total_number_of_frames = END_FRAME - START_FRAME\n",
    "print(f'Total number of frames to process: {total_number_of_frames}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def get_frame(cap, frame_number):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        raise ValueError(f\"Failed to read frame at position {frame_number}\")\n",
    "    \n",
    "    # Resize frame to standard resolution\n",
    "    if RESOLUTION != STANDARD_RESOLUTION:\n",
    "        frame = cv2.resize(frame, STANDARD_RESOLUTION)\n",
    "    \n",
    "    # frame = cv2.resize(frame, (640, 480))\n",
    "    processed_frame = preprocess_frame(frame)\n",
    "    return frame, processed_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoBuilder:\n",
    "    def __init__(self, filename, fps):\n",
    "        self.fps = fps\n",
    "        self.output_file = filename\n",
    "        self.recorder = None\n",
    "\n",
    "    def add_frame(self, frame):\n",
    "        if self.recorder is None:\n",
    "            self.recorder = cv2.VideoWriter(self.output_file, cv2.VideoWriter_fourcc(*'XVID'), self.fps, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        self.recorder.write(frame)\n",
    "\n",
    "    def stop_recording(self):\n",
    "        if self.recorder is not None:\n",
    "            self.recorder.release()\n",
    "            self.recorder = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo Segmentation Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# segmentation model\n",
    "model = YOLO(\"yolo11m-seg.pt\")  # load a pretrained model (recommended for inference)\n",
    "\n",
    "def get_vehicle_mask(_frame):\n",
    "    # run the model on the frame\n",
    "    results = model([_frame], verbose=False)\n",
    "\n",
    "    # get the first result (the only one in this case)\n",
    "    if len(results) == 0:\n",
    "        print(\"No results found.\")\n",
    "        return np.ones((_frame.shape[0], _frame.shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    result = results[0]\n",
    "    # result.save(filename=\"result.jpg\")\n",
    "\n",
    "    if result.masks is None or result.boxes is None:\n",
    "        print(\"No masks or boxes found.\")\n",
    "        return np.ones((_frame.shape[0], _frame.shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    masks = result.masks.data.cpu().numpy()  \n",
    "    class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    vehicle_classes = {\"car\", \"truck\", \"bus\", \"motorcycle\", \"bicycle\"}\n",
    "    _mask = np.zeros((_frame.shape[0], _frame.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    for i, class_id in enumerate(class_ids):\n",
    "        class_name = model.names[class_id]\n",
    "        if class_name in vehicle_classes:\n",
    "            resized_mask = cv2.resize(\n",
    "                masks[i].astype(np.uint8),\n",
    "                (_frame.shape[1], _frame.shape[0]),  # (width, height)\n",
    "                interpolation=cv2.INTER_NEAREST\n",
    "            )\n",
    "            _mask = np.logical_or(_mask, resized_mask).astype(np.uint8)\n",
    "\n",
    "    vehicle_mask = _mask.astype(np.uint8)  # 0 or 1\n",
    "\n",
    "    return vehicle_mask\n",
    "\n",
    "\n",
    "# frame = get_frame(cap, 0)[0]\n",
    "\n",
    "# # get the vehicle mask\n",
    "# vehicle_seg_mask = get_vehicle_mask(frame)\n",
    "\n",
    "# plt.imshow(vehicle_seg_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_point_on_vehicle(point, mask):\n",
    "    x, y = int(point[0]), int(point[1])\n",
    "    if x < 0 or y < 0 or x >= mask.shape[1] or y >= mask.shape[0]:\n",
    "        return False\n",
    "    return mask[y, x] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Vector Detection\n",
    "\n",
    "initialise motion detection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for Shi-Tomasi corner detection\n",
    "feature_params = dict( maxCorners = 40, # 50 for non grid based\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 20,\n",
    "                       blockSize = 7,)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# minimum displacement\n",
    "MINIMUM_TRACKED_POINTS = 400\n",
    "MINIMUM_DISPLACEMENT = 1\n",
    "MAXIMUM_TRAJECTORY_LENGTH = 50\n",
    "\n",
    "# R-VP parameters\n",
    "THRESHOLD_REMOVE_SHORT_TRAJECTORIES = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corner detection mask to select new points from a distance (Region of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame, _ = get_frame(cap, 0)\n",
    "\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "mask = np.ones((frame_height, frame_width), dtype=np.uint8)\n",
    "\n",
    "# apply mask to select new points from a distance (Region of interest)\n",
    "mask[-200:] = 0\n",
    "mask[:, :700] = 0\n",
    "mask[:, -700:] = 0\n",
    "\n",
    "masked_bgr = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "masked_bgr = cv2.cvtColor(masked_bgr, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(masked_bgr)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Feature Detection\n",
    "Detect corners using Shi-Tomasi corner detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_corners = []\n",
    "\n",
    "# corner_cache = {} # cache to optimise when tweaking parameters\n",
    "\n",
    "# def get_points_of_frame(frame_number):\n",
    "#     if frame_number in corner_cache:\n",
    "#         return corner_cache.get(frame_number)\n",
    "    \n",
    "#     _, frame = get_frame(cap, frame_number) # using processed frame, not original\n",
    "\n",
    "#     # shi-tomasi corner detection\n",
    "#     corners = cv2.goodFeaturesToTrack(frame, mask = mask, **feature_params)\n",
    "\n",
    "#     if corners is None:\n",
    "#         print(f\"No corners found in frame {frame_number}.\")\n",
    "#         return None\n",
    "\n",
    "#     corner_cache[frame_number] = corners\n",
    "#     return corners\n",
    "\n",
    "def split_into_grid(frame, grid_size):\n",
    "    height, width = frame.shape\n",
    "    grid_height, grid_width = grid_size\n",
    "    grid_height = height // grid_height\n",
    "    grid_width = width // grid_width\n",
    "\n",
    "    grid = []\n",
    "    for i in range(0, height, grid_height):\n",
    "        for j in range(0, width, grid_width):\n",
    "            grid.append(\n",
    "                [i,j,frame[i:i+grid_height, j:j+grid_width]]\n",
    "            )\n",
    "\n",
    "    return grid\n",
    "\n",
    "def get_points_of_frame(frame_number):\n",
    "    _, frame = get_frame(cap, frame_number) # using processed frame, not original\n",
    "    frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    grid = split_into_grid(frame, (4, 4))\n",
    "\n",
    "    corner_list = []\n",
    "\n",
    "    for g in grid:\n",
    "        # shi-tomasi corner detection\n",
    "        new_corners = cv2.goodFeaturesToTrack(g[2], **feature_params)\n",
    "        if new_corners is None:\n",
    "            continue\n",
    "        \n",
    "        for corner in new_corners:\n",
    "            corner[0][0] += g[1]\n",
    "            corner[0][1] += g[0]\n",
    "            corner_list.append(corner[0])\n",
    "\n",
    "    corner_list = np.array(corner_list, dtype=np.float32)\n",
    "    corner_list = corner_list.reshape(-1, 1, 2)\n",
    "\n",
    "    return corner_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = get_frame(cap, 0)[0]\n",
    "corners = get_points_of_frame(0)\n",
    "\n",
    "print(f'Example frame {0} with {len(corners)} corners')\n",
    "\n",
    "frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner[0]\n",
    "    cv2.circle(frame, (int(x), int(y)), 3, 255, -1)\n",
    "\n",
    "# draw (8,8) grid\n",
    "for i in range(0, frame.shape[0], frame.shape[0]//4):\n",
    "    cv2.line(frame, (0, i), (frame.shape[1], i), 255, 1)\n",
    "\n",
    "for i in range(0, frame.shape[1], frame.shape[1]//4):\n",
    "    cv2.line(frame, (i, 0), (i, frame.shape[0]), 255, 1)\n",
    "    \n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Tracking using Lucas-Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output video of the motion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random colours to label different lines\n",
    "color = np.random.randint(0, 255, (400000, 3))\n",
    "\n",
    "def get_frame_with_trajectories(frame_number, trajectories):\n",
    "    original_frame, _ = get_frame(cap, frame_number)\n",
    "\n",
    "    original_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if RUN_WITH_YOLO_SEG:\n",
    "        # Draw the mask on the original frame with 50% opacity\n",
    "        vehicle_mask = get_vehicle_mask(original_frame)  # values 0 or 1\n",
    "        colored_mask = np.zeros_like(original_frame)\n",
    "        colored_mask[vehicle_mask == 1] = (0, 0, 255)  \n",
    "        original_frame = cv2.addWeighted(original_frame, 1.0, colored_mask, 0.5, 0)\n",
    "    \n",
    "    # Draw the full trajectories\n",
    "    for start_position, points in trajectories.items():\n",
    "        color_idx = hash(start_position) % len(color) # Get a consistent color based on start position\n",
    "        for j in range(1, len(points)): # Draw a line between all consecutive points\n",
    "            a, b = points[j]\n",
    "            c, d = points[j - 1]\n",
    "            original_frame = cv2.line(original_frame, (int(a), int(b)), (int(c), int(d)), color[color_idx].tolist(), 2)\n",
    "\n",
    "    # Draw current points as circles\n",
    "    for start_position, points in trajectories.items():\n",
    "        color_idx = hash(start_position) % len(color) # Get a consistent color based on start position\n",
    "        a, b = points[-1] # draw the last point\n",
    "        original_frame = cv2.circle(original_frame, (int(a), int(b)), 5, color[color_idx].tolist(), -1)\n",
    "\n",
    "    return original_frame\n",
    "\n",
    "\n",
    "# create frames with trajectories and save them to a video\n",
    "def output_video_of_trajectories(frame_trajectories, _start_frame, _end_frame, filename):\n",
    "    video = VideoBuilder(filename, 30)\n",
    "    for i in range(_start_frame, _end_frame):\n",
    "        frame_number = i\n",
    "        trajectories = frame_trajectories[i - _start_frame]\n",
    "        frame = get_frame_with_trajectories(frame_number, trajectories)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        video.add_frame(frame)\n",
    "    video.stop_recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stationary points\n",
    "Filter and remove points that are not moving more than Min_displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_minimum_displacement(good_old, good_new):\n",
    "    \"\"\"\n",
    "    Filter out points that have not moved significantly.\n",
    "\n",
    "    Args:\n",
    "        good_old: old features from good matches\n",
    "        good_new: new features from good matches\n",
    "\n",
    "    Returns:\n",
    "        list: filtered good_old and good_new points\n",
    "    \"\"\"\n",
    "    new_good_old = []\n",
    "    new_good_new = []\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        new_x, new_y = new.ravel()\n",
    "        old_x, old_y = old.ravel()\n",
    "        if abs(new_x - old_x) > MINIMUM_DISPLACEMENT or abs(new_y - old_y) > MINIMUM_DISPLACEMENT:\n",
    "            new_good_old.append(old)\n",
    "            new_good_new.append(new)\n",
    "    return np.array(new_good_old), np.array(new_good_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clip max trajectory length\n",
    "Hard limit length of a tracked point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_max_trajectory(trajectory_list):\n",
    "    \"\"\"\n",
    "    Clip the trajectory list to the maximum length.\n",
    "\n",
    "    Args:\n",
    "        trajectory_list (list): list of trajectory records\n",
    "\n",
    "    Returns:\n",
    "        list: clipped trajectory list\n",
    "    \"\"\"\n",
    "    return trajectory_list[-MAXIMUM_TRAJECTORY_LENGTH:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if trajectories moving towards edge of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trajectories_not_diverging_from_center_x_axis(trajectories, center_x):\n",
    "    \"\"\"\n",
    "    Remove trajectories that are not diverging from the center.\n",
    "\n",
    "    Args:\n",
    "        trajectories (dict): dictionary of trajectories\n",
    "\n",
    "    Returns:\n",
    "        dict: filtered trajectories\n",
    "    \"\"\"\n",
    "    filtered_trajectories = {}\n",
    "    for start_position, points in trajectories.items():\n",
    "        if len(points) > 1:\n",
    "            # Calculate the distance from the first point to the last point\n",
    "            # print(f\"Trajectory {start_position}: {points}\")\n",
    "            x_diff = points[-1][0] - points[0][0]\n",
    "\n",
    "            center_x_diff = points[-1][0] - center_x\n",
    "\n",
    "            # Check if the trajectory is diverging from the center\n",
    "            if (x_diff< 0 and center_x_diff < 0) or (x_diff > 0 and center_x_diff > 0):\n",
    "                filtered_trajectories[start_position] = points\n",
    "    return filtered_trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform tracking\n",
    "- Points over many consecutive frames are considered stable motion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_frame_trajectories(start_frame=0, end_frame=None):\n",
    "    all_frame_trajectories = [] # store all trajectories for each frame\n",
    "\n",
    "    # initial frame and starting points\n",
    "    p0 = get_points_of_frame(start_frame)\n",
    "    _, last_frame = get_frame(cap, start_frame)\n",
    "\n",
    "    # Init tracked points\n",
    "    trajectories = {tuple(p.ravel()): [p.ravel()] for p in p0}\n",
    "\n",
    "    # Store initial trajectories\n",
    "    all_frame_trajectories.append(copy.deepcopy(trajectories))\n",
    "\n",
    "    if end_frame is None:\n",
    "        end_frame = total_number_of_frames\n",
    "\n",
    "    # for each frame at an increment of 1\n",
    "    for i in range(start_frame + 1, end_frame):\n",
    "        colour_frame , frame_gray = get_frame(cap, i)\n",
    "        \n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(last_frame, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        if p1 is not None:\n",
    "            good_new = p1[st==1]\n",
    "            good_old = p0[st==1]\n",
    "\n",
    "        # Filter out points that have not moved above a given threshold\n",
    "        good_old, good_new = filter_for_minimum_displacement(good_old, good_new)\n",
    "\n",
    "        # get a tracked point using the last tracked position as the key\n",
    "        new_trajectories = {}\n",
    "\n",
    "\n",
    "        for new, old in zip(good_new, good_old):\n",
    "            start_position = tuple(old.ravel())  # Use the original position as the key\n",
    "            next_iterations_start_position = tuple(new.ravel())  # Use the new position as the key for the next iteration\n",
    "\n",
    "            # Check if the new point is on a vehicle in the mask\n",
    "            if start_position in trajectories:\n",
    "                # Update tracked points with new position\n",
    "                trajectories[start_position].append(tuple(new.ravel()))\n",
    "                # create a new set of trajectories with the new position as the key\n",
    "                new_trajectories[next_iterations_start_position] = clip_max_trajectory(trajectories[start_position])\n",
    "\n",
    "        # Replace old trajectories with updated ones that exclude lost points\n",
    "        trajectories = new_trajectories\n",
    "\n",
    "        # remove trajectories that are not diverging from the center\n",
    "        center_x = frame_gray.shape[1] // 2\n",
    "        trajectories = remove_trajectories_not_diverging_from_center_x_axis(trajectories, center_x)\n",
    "\n",
    "        if RUN_WITH_YOLO_SEG:\n",
    "            vehicle_mask = get_vehicle_mask(colour_frame)\n",
    "            filtered = {}\n",
    "            for start, pts in trajectories.items():\n",
    "                last_pt = pts[-1]\n",
    "                if not is_point_on_vehicle(last_pt, vehicle_mask):\n",
    "                    filtered[start] = pts\n",
    "            trajectories = filtered\n",
    "\n",
    "\n",
    "        # make a record of the trajectories at frame i\n",
    "        all_frame_trajectories.append(copy.deepcopy(trajectories))\n",
    "\n",
    "        # prepare for next iteration\n",
    "        last_frame = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "        # keep adding points once fall below a minimum threshold\n",
    "        if len(p0) < MINIMUM_TRACKED_POINTS:\n",
    "            new_points = get_points_of_frame(i)\n",
    "            p0 = np.concatenate((p0, new_points), axis=0)\n",
    "            # add new points to next tracked trajectories\n",
    "            for new_p in new_points:\n",
    "                start_position = tuple(new_p.ravel())\n",
    "                if start_position not in trajectories:\n",
    "                    trajectories[start_position] = [tuple(new_p.ravel())]\n",
    "    \n",
    "    return all_frame_trajectories\n",
    "\n",
    "print(\"Tracking trajectories...\")\n",
    "all_frame_trajectories = get_all_frame_trajectories(START_FRAME, END_FRAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display tracked points counts by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, total_number_of_frames)\n",
    "y = [len(frame_trajectories) for frame_trajectories in all_frame_trajectories]\n",
    "\n",
    "plt.axhline(y=MINIMUM_TRACKED_POINTS, color='r', linestyle='-')\n",
    "plt.title('Number of tracked points over time')\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Number of tracked points')\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_frame = 280\n",
    "\n",
    "if END_FRAME is not None:\n",
    "    example_frame = 50\n",
    "\n",
    "# filter related frame for short trajectories\n",
    "trajectories = all_frame_trajectories[example_frame]\n",
    "ignore_short_history_trajectories = {start_position: points for start_position, points in trajectories.items() if len(points) > THRESHOLD_REMOVE_SHORT_TRAJECTORIES}\n",
    "\n",
    "# display frame with trajectories\n",
    "frame = get_frame_with_trajectories(example_frame, ignore_short_history_trajectories)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing stationary object motion vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove vector paths with low momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-VP Voting\n",
    "Using RANSAC to find the best vanishing point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANSAC voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_vanishing_point(line_segments, iterations=500, threshold=10,  inlier_ratio=0.6):\n",
    "    best_vanishing_point = None\n",
    "    max_inliers = 0\n",
    "    total_segments = len(line_segments)\n",
    "    \n",
    "    # pre-solve slopes and intercepts\n",
    "    slopes = []\n",
    "    intercepts = []\n",
    "    for (start, end) in line_segments:\n",
    "        x1, y1 = start\n",
    "        x2, y2 = end\n",
    "        if x2 != x1:  # Non-vertical line\n",
    "            m = (y2 - y1) / (x2 - x1)\n",
    "            c = y1 - m * x1\n",
    "        else:  # Vertical line case, set slope to None\n",
    "            m, c = None, x1\n",
    "        slopes.append(m)\n",
    "        intercepts.append(c)\n",
    "    \n",
    "    slopes = np.array(slopes)\n",
    "    intercepts = np.array(intercepts)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Randomly select two line segments\n",
    "        idx1, idx2 = np.random.choice(total_segments, 2, replace=False)\n",
    "        \n",
    "        m1, c1 = slopes[idx1], intercepts[idx1]\n",
    "        m2, c2 = slopes[idx2], intercepts[idx2]\n",
    "        \n",
    "        # Skip if parallel or identical (no unique intersection)\n",
    "        if m1 == m2:\n",
    "            continue\n",
    "        \n",
    "        # Calculate intersection point\n",
    "        if m1 is not None and m2 is not None:\n",
    "            # Both lines are non-vertical\n",
    "            x_intersect = (c2 - c1) / (m1 - m2)\n",
    "            y_intersect = m1 * x_intersect + c1\n",
    "        elif m1 is None:  # Line 1 is vertical\n",
    "            x_intersect = c1\n",
    "            y_intersect = m2 * x_intersect + c2\n",
    "        elif m2 is None:  # Line 2 is vertical\n",
    "            x_intersect = c2\n",
    "            y_intersect = m1 * x_intersect + c1\n",
    "        \n",
    "        intersection_point = np.array([x_intersect, y_intersect])\n",
    "        \n",
    "        # Calculate distances for all line segments to this intersection point\n",
    "        distances = []\n",
    "        for i, (m, c) in enumerate(zip(slopes, intercepts)):\n",
    "            if m is not None:\n",
    "                # Non-vertical line: calculate perpendicular distance\n",
    "                y_hat = m * x_intersect + c\n",
    "                distance = abs(y_hat - y_intersect)\n",
    "            else:\n",
    "                # Vertical line: distance is horizontal distance\n",
    "                distance = abs(x_intersect - c)\n",
    "            distances.append(distance)\n",
    "        \n",
    "        distances = np.array(distances)\n",
    "        inliers = distances < threshold\n",
    "        num_inliers = np.sum(inliers)\n",
    "        \n",
    "        # Update best vanishing point if this one has more inliers\n",
    "        if num_inliers > max_inliers:\n",
    "            best_vanishing_point = intersection_point\n",
    "            max_inliers = num_inliers\n",
    "            \n",
    "            # Early stopping if enough inliers found\n",
    "            if max_inliers / total_segments >= inlier_ratio:\n",
    "                break\n",
    "    \n",
    "    return best_vanishing_point, max_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac_vectors = []\n",
    "\n",
    "for start_position, points in ignore_short_history_trajectories.items():\n",
    "    for i in range(1, len(points)):\n",
    "        # Store both start and end points of each vector\n",
    "        start_point = points[i - 1]\n",
    "        end_point = points[i]\n",
    "        ransac_vectors.append([start_point, end_point])\n",
    "\n",
    "ransac_vectors = np.array(ransac_vectors)\n",
    "\n",
    "vanishing_point, inliers_count = find_vanishing_point(ransac_vectors)\n",
    "print(\"Vanishing Point:\", vanishing_point)\n",
    "print(\"Number of Inliers:\", inliers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = get_frame_with_trajectories(example_frame, ignore_short_history_trajectories)\n",
    "\n",
    "# Draw vp\n",
    "if vanishing_point is not None:\n",
    "    frame = cv2.circle(frame, tuple(vanishing_point.astype(int)), 10, (0, 255, 0), 6)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find R-VP using RANSAC on all frames\n",
    "Run R-VP voting on all frames and add the best vanishing point to all_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Processing all frames for vanishing points\")\n",
    "all_vp = []\n",
    "\n",
    "for i in range(total_number_of_frames):\n",
    "    trajectories = all_frame_trajectories[i]\n",
    "    ignore_short_history_trajectories = {start_position: points for start_position, points in trajectories.items() if len(points) > THRESHOLD_REMOVE_SHORT_TRAJECTORIES}\n",
    "    ransac_vectors = []\n",
    "\n",
    "    for start_position, points in ignore_short_history_trajectories.items():\n",
    "        for i in range(1, len(points)):\n",
    "            start_point = points[i - 1]\n",
    "            end_point = points[i]\n",
    "            ransac_vectors.append([start_point, end_point])\n",
    "\n",
    "    ransac_vectors = np.array(ransac_vectors)\n",
    "\n",
    "    if len(ransac_vectors) < 2:\n",
    "        all_vp.append(np.array([0, 0]))\n",
    "        continue\n",
    "    vanishing_point, inliers_count = find_vanishing_point(ransac_vectors)\n",
    "    all_vp.append(vanishing_point)\n",
    "\n",
    "all_vp = np.array(all_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_video_of_R_VP(VP, trajectories, _start_frame, _end_frame, filename):\n",
    "    video = VideoBuilder(filename, 30)\n",
    "    print(f\"Outputting video to {filename} from {_start_frame} to {_end_frame}\")\n",
    "    for i in range(_end_frame - _start_frame):\n",
    "        frame_number = _start_frame + i\n",
    "        # print(f\"Processing frame {frame_number}\")\n",
    "        vanishing_point = VP[i]\n",
    "        frame = get_frame_with_trajectories(frame_number, trajectories[i])\n",
    "        if vanishing_point is not None:\n",
    "            frame = cv2.circle(frame, tuple(vanishing_point.astype(int)), 10, (0, 255, 0), 5)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        video.add_frame(frame)\n",
    "    video.stop_recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Fixed Road Vanishing Point for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove run up frames\n",
    "print(\"Outputting video of R-VP and average_vp\")\n",
    "START_FRAME_ADJUSTED = START_FRAME + RUN_UP_FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_vanishing_point(vp_list):\n",
    "    \"\"\"\n",
    "    Calculate the average vanishing point from a list of vanishing points.\n",
    "\n",
    "    Args:\n",
    "        vp_list (list): list of vanishing points\n",
    "\n",
    "    Returns:\n",
    "        np.array: average vanishing point\n",
    "    \"\"\"\n",
    "    if len(vp_list) == 0:\n",
    "        return None\n",
    "    return np.mean(vp_list, axis=0)\n",
    "\n",
    "\n",
    "vp_after_run_up_removal = all_vp[RUN_UP_FRAMES:]\n",
    "trajectories_after_run_up_removal = all_frame_trajectories[RUN_UP_FRAMES:]\n",
    "\n",
    "average_vp = get_average_vanishing_point(vp_after_run_up_removal)\n",
    "\n",
    "if STANDARD_RESOLUTION != RESOLUTION:\n",
    "    print(f\"Average vanishing point was: {average_vp}\")\n",
    "    average_vp_x = average_vp[0] * (RESOLUTION[0] / STANDARD_RESOLUTION[0])\n",
    "    average_vp_y = average_vp[1] * (RESOLUTION[1] / STANDARD_RESOLUTION[1])\n",
    "    average_vp = np.array([average_vp_x, average_vp_y])\n",
    "    print(\"Average vanishing point after scaling:\", average_vp)\n",
    "else:\n",
    "    print(\"Resolution as expected: \", RESOLUTION)\n",
    "\n",
    "average_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_vp_file is {file_name}_{start_frame}_{end_frame}_average_vp.txt\n",
    "\n",
    "average_vp_file = f'{OUTPUT_FOLDER}/{START_FRAME_ADJUSTED}_{END_FRAME}_average_vp.txt'\n",
    "with open(average_vp_file, 'w') as f:\n",
    "    f.write(f'{average_vp[0]}, {average_vp[1]}')\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Outputting video with trajectories to {OUTPUT_FOLDER}/{START_FRAME}_{END_FRAME}_trajectories.avi')\n",
    "# output_video_of_trajectories(all_frame_trajectories, f'{OUTPUT_FOLDER}/{START_FRAME}_{END_FRAME}_trajectories.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_of_R_VP(vp_after_run_up_removal, trajectories_after_run_up_removal, START_FRAME_ADJUSTED, END_FRAME, f'{OUTPUT_FOLDER}/{START_FRAME_ADJUSTED}_{END_FRAME}_vp.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
