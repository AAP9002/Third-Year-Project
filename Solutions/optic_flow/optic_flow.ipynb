{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optic Flow\n",
    "Inspired by: A Robust Road Vanishing Point Detection Adapted to the\n",
    "Real-World Driving Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the:\n",
    "1. analysis,\n",
    "2. stable motion detection\n",
    "3. stationary point-based motion vector selection\n",
    "4. angle-based RANSAC\n",
    "(RANdom SAmple Consensus) voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# create temp folder\n",
    "if not os.path.exists('temp'):\n",
    "    os.makedirs('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"test_20s_video.MP4\"\n",
    "cap = cv2.VideoCapture(file)\n",
    "total_number_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # mask bottom\n",
    "    gray[-400:] = 0\n",
    "    # blur\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    return gray\n",
    "\n",
    "def get_frame(cap, frame_number):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    processed_frame = preprocess_frame(frame)\n",
    "    return frame, processed_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoBuilder:\n",
    "    def __init__(self, filename, fps):\n",
    "        self.fps = fps\n",
    "        self.output_file = filename\n",
    "        self.recorder = None\n",
    "\n",
    "    def add_frame(self, frame):\n",
    "        if self.recorder is None:\n",
    "            self.recorder = cv2.VideoWriter(self.output_file, cv2.VideoWriter_fourcc(*'XVID'), self.fps, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        self.recorder.write(frame)\n",
    "\n",
    "    def stop_recording(self):\n",
    "        if self.recorder is not None:\n",
    "            self.recorder.release()\n",
    "            self.recorder = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Vector Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 500,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Feature Detection\n",
    "Detect corners using Shi-Tomasi corner detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! any changes to this function will require re-running the entire script and clearing temp cache\n",
    "all_corners = []\n",
    "\n",
    "corner_cache = {}\n",
    "\n",
    "def get_points_of_frame(frame_number):\n",
    "    if frame_number in corner_cache:\n",
    "        return corner_cache.get(frame_number)\n",
    "    \n",
    "    original_frame, frame = get_frame(cap, frame_number)\n",
    "\n",
    "    # shi-tomasi corner detection\n",
    "    corners = cv2.goodFeaturesToTrack(frame, mask = None, **feature_params)\n",
    "\n",
    "    if corners is not None:\n",
    "        for corner in corners:\n",
    "            x, y = corner.ravel()\n",
    "            cv2.circle(original_frame, (int(x), int(y)), 3, 255, -1)\n",
    "\n",
    "    corner_cache[frame_number] = corners\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Tracking using Lucas-Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recorder\n",
    "record = VideoBuilder(fps=cap.get(cv2.CAP_PROP_FPS), filename='all_optic_flow.avi')\n",
    "\n",
    "# initial frame\n",
    "p0 = get_points_of_frame(0)\n",
    "_, last_frame = get_frame(cap, 0)\n",
    "\n",
    "\n",
    "# random colours to label different lines\n",
    "color = np.random.randint(0, 255, (400000, 3))\n",
    "\n",
    "\n",
    "# Dictionary to store trajectories of each point\n",
    "trajectories = {tuple(p.ravel()): [p] for p in p0}\n",
    "\n",
    "for i in range(1, total_number_of_frames):\n",
    "    frame, frame_gray = get_frame(cap, i)\n",
    "    \n",
    "    mask = np.zeros_like(frame)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(last_frame, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "    new_trajectories = {}\n",
    "    for new, old in zip(good_new, good_old):\n",
    "        start_position = tuple(old.ravel())  # Use the original position as the key\n",
    "        next_iterations_start_position = tuple(new.ravel())  # Use the new position as the key for the next iteration\n",
    "        if start_position in trajectories:\n",
    "            # Append new position to the trajectory with the same start position\n",
    "            trajectories[start_position].append(new)\n",
    "            # Keep this trajectory in the new set of trajectories\n",
    "            new_trajectories[next_iterations_start_position] = trajectories[start_position]\n",
    "\n",
    "    # Replace old trajectories with updated ones that exclude lost points\n",
    "    trajectories = new_trajectories\n",
    "\n",
    "    # Draw the full trajectories\n",
    "    for start_position, points in trajectories.items():\n",
    "        color_idx = hash(start_position) % len(color)  # Get a consistent color for each start position\n",
    "        for j in range(1, len(points)):\n",
    "            a, b = points[j].ravel()\n",
    "            c, d = points[j - 1].ravel()\n",
    "            mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[color_idx].tolist(), 2)\n",
    "\n",
    "    # Draw current points as circles\n",
    "    for start_position, points in trajectories.items():\n",
    "        color_idx = hash(start_position) % len(color)  # Re-use the consistent color\n",
    "        a, b = points[-1].ravel()  # Last known position\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[color_idx].tolist(), -1)\n",
    "\n",
    "    # draw on image\n",
    "    frame = cv2.add(frame, mask)\n",
    "\n",
    "    # save image\n",
    "    record.add_frame(frame)\n",
    "\n",
    "    last_frame = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    if len(p0) < 400:\n",
    "        new_points = get_points_of_frame(i)\n",
    "        p0 = np.concatenate((p0, new_points), axis=0)\n",
    "        for new_p in new_points:\n",
    "            start_position = tuple(new_p.ravel())\n",
    "            if start_position not in trajectories:\n",
    "                trajectories[start_position] = [new_p]\n",
    "\n",
    "record.stop_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
